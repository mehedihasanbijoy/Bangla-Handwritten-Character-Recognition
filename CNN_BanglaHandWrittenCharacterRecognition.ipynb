{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook you have seen in the overview video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', input_shape = (40, 40, 3)))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(.2))\n",
    "\n",
    "classifier.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(.2))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(.2))\n",
    "\n",
    "classifier.add(Dense(units = 50, activation = 'softmax'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the CNN model to the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = .2, rotation_range = 25)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('Dataset/Train', target_size = (40, 40), \n",
    "                                                 batch_size = 32, class_mode = 'categorical')\n",
    "test_set = test_datagen.flow_from_directory('Dataset/Test', target_size = (40, 40), \n",
    "                                                 batch_size = 32, class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 1092s 91ms/step - loss: 0.6476 - accuracy: 0.8038 - val_loss: 0.4770 - val_accuracy: 0.8930\n",
      "Epoch 2/10\n",
      "12000/12000 [==============================] - 1087s 91ms/step - loss: 0.2762 - accuracy: 0.9098 - val_loss: 0.1934 - val_accuracy: 0.9208\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 1086s 91ms/step - loss: 0.2028 - accuracy: 0.9332 - val_loss: 0.2739 - val_accuracy: 0.9253\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 1088s 91ms/step - loss: 0.1717 - accuracy: 0.9438 - val_loss: 1.0519 - val_accuracy: 0.9176\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 1083s 90ms/step - loss: 0.1558 - accuracy: 0.9492 - val_loss: 0.2031 - val_accuracy: 0.9191\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 1082s 90ms/step - loss: 0.1419 - accuracy: 0.9537 - val_loss: 0.0907 - val_accuracy: 0.9287\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 1083s 90ms/step - loss: 0.1359 - accuracy: 0.9563 - val_loss: 0.0385 - val_accuracy: 0.9236\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 1099s 92ms/step - loss: 0.1293 - accuracy: 0.9586 - val_loss: 0.3130 - val_accuracy: 0.9238\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 1082s 90ms/step - loss: 0.1235 - accuracy: 0.9607 - val_loss: 0.1374 - val_accuracy: 0.9303\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 1079s 90ms/step - loss: 0.1203 - accuracy: 0.9614 - val_loss: 0.2892 - val_accuracy: 0.9269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1d31288e8c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set, steps_per_epoch = 12000, epochs = 10,\n",
    "                        validation_data = test_set, validation_steps = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 38, 38, 128)       3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                6450      \n",
      "=================================================================\n",
      "Total params: 608,242\n",
      "Trainable params: 608,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "classifier_json = classifier.to_json()\n",
    "\n",
    "with open(\"CNN_BanglaHandWrittenCharacterRecognition.json\", \"w\") as json_file:\n",
    "    json_file.write(classifier_json)\n",
    "    \n",
    "classifier.save_weights(\"CNN_BanglaHandWrittenCharacterRecognition.h5\")\n",
    "print('Saved model to disk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a graphical user interface to draw the character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import ImageTk, ImageDraw, Image\n",
    "from tkinter import *\n",
    "from keras.preprocessing import image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_image():\n",
    "    width = 256\n",
    "    height = 256\n",
    "    center = height // 2\n",
    "    white = (255, 255, 255)\n",
    "    green = (0, 128, 0)\n",
    "    \n",
    "    def save():\n",
    "        filename = 'C:/Users/MHB/Desktop/BHWCC/Dataset/SinglePrediction/image.jpg'\n",
    "        image.save(filename)\n",
    "        \n",
    "    def paint(event):\n",
    "        x1, y1 = (event.x - 1), (event.y - 1)\n",
    "        x2, y2 = (event.x + 1), (event.y + 1)\n",
    "        cv.create_oval(x1, y1, x2, y2, fill = 'black', width = 30)\n",
    "        draw.line([x1, y1, x2, y2], fill = 'black', width = 30)\n",
    "        \n",
    "    root = Tk()\n",
    "    \n",
    "    cv = Canvas(root, width = width, height = height, bg = 'white')\n",
    "    cv.pack()\n",
    "    \n",
    "    image = PIL.Image.new('RGB', (width, height), white)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    cv.pack(expand = YES, fill = BOTH)\n",
    "    cv.bind(\"<B1-Motion>\", paint)\n",
    "    \n",
    "    button = Button(text = 'Save', command = save)\n",
    "    button.pack()\n",
    "    \n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_character(res):\n",
    "    if res == 0:\n",
    "        print('prediction : অ')\n",
    "    elif res == 1:\n",
    "        print('prediction : আ')\n",
    "    elif res == 2:\n",
    "        print('prediction : ই')\n",
    "    elif res == 3:\n",
    "        print('prediction : ঈ')\n",
    "    elif res == 4:\n",
    "        print('prediction : উ')\n",
    "    elif res == 5:\n",
    "        print('prediction : ঊ')\n",
    "    elif res == 6:\n",
    "        print('prediction : ঋ')\n",
    "    elif res == 7:\n",
    "        print('prediction : এ')\n",
    "    elif res == 8:\n",
    "        print('prediction : ঐ')\n",
    "    elif res == 9:\n",
    "        print('prediction : ও')\n",
    "    elif res == 10:\n",
    "        print('prediction : ঔ')\n",
    "    elif res == 11:\n",
    "        print('prediction : ক')\n",
    "    elif res == 12:\n",
    "        print('prediction : খ')\n",
    "    elif res == 13:\n",
    "        print('prediction : গ')\n",
    "    elif res == 14:\n",
    "        print('prediction : ঘ')\n",
    "    elif res == 15:\n",
    "        print('prediction : ঙ')\n",
    "    elif res == 16:\n",
    "        print('prediction : চ')\n",
    "    elif res == 17:\n",
    "        print('prediction : ছ')\n",
    "    elif res == 18:\n",
    "        print('prediction : জ')\n",
    "    elif res == 19:\n",
    "        print('prediction : ঝ')\n",
    "    elif res == 20:\n",
    "        print('prediction : ঞ')\n",
    "    elif res == 21:\n",
    "        print('prediction : ট')\n",
    "    elif res == 22:\n",
    "        print('prediction : ঠ')\n",
    "    elif res == 23:\n",
    "        print('prediction : ড')\n",
    "    elif res == 24:\n",
    "        print('prediction : ঢ')\n",
    "    elif res == 25:\n",
    "        print('prediction : ণ')\n",
    "    elif res == 26:\n",
    "        print('prediction : ত')\n",
    "    elif res == 27:\n",
    "        print('prediction : থ')\n",
    "    elif res == 28:\n",
    "        print('prediction : দ')\n",
    "    elif res == 29:\n",
    "        print('prediction : ধ')\n",
    "    elif res == 30:\n",
    "        print('prediction : ন')\n",
    "    elif res == 31:\n",
    "        print('prediction : প')\n",
    "    elif res == 32:\n",
    "        print('prediction : ফ')\n",
    "    elif res == 33:\n",
    "        print('prediction : ব')\n",
    "    elif res == 34:\n",
    "        print('prediction : ভ')\n",
    "    elif res == 35:\n",
    "        print('prediction : ম')\n",
    "    elif res == 36:\n",
    "        print('prediction : য')\n",
    "    elif res == 37:\n",
    "        print('prediction : র')\n",
    "    elif res == 38:\n",
    "        print('prediction : ল')\n",
    "    elif res == 39:\n",
    "        print('prediction : শ')\n",
    "    elif res == 40:\n",
    "        print('prediction : ষ')\n",
    "    elif res == 41:\n",
    "        print('prediction : স')\n",
    "    elif res == 42:\n",
    "        print('prediction : হ')\n",
    "    elif res == 43:\n",
    "        print('prediction : ড়')\n",
    "    elif res == 44:\n",
    "        print('prediction : ঢ়')\n",
    "    elif res == 45:\n",
    "        print('prediction : য়')\n",
    "    elif res == 46:\n",
    "        print('prediction : ৎ')\n",
    "    elif res == 47:\n",
    "        print('prediction : ং')\n",
    "    elif res == 48:\n",
    "        print('prediction : ঃ')\n",
    "    else:\n",
    "        print('prediction : ঁ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def single_prediction(test_img):\n",
    "    test_img_arr = image.img_to_array(test_img)\n",
    "    test_img_arr = np.expand_dims(test_img_arr, axis = 0)\n",
    "    prediction = classifier.predict(test_img_arr)\n",
    "    result = np.argmax(prediction, axis = 1)\n",
    "    determine_character(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_created_image():\n",
    "    os.remove('C:/Users/MHB/Desktop/BHWCC/Dataset/SinglePrediction/image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_n_guess_the_character():\n",
    "    create_new_image()\n",
    "    test_img = image.load_img('C:/Users/MHB/Desktop/BHWCC/Dataset/SinglePrediction/image.jpg', target_size = (40, 40, 3))\n",
    "    single_prediction(test_img)\n",
    "    plt.imshow(test_img)\n",
    "    delete_created_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction : অ\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_n_guess_the_character()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
