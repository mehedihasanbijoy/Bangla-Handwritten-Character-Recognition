{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Veams-yTpI0e"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "file_name = \"Dataset.zip\"\n",
    "\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "  zip.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XECEv7NWrXCj"
   },
   "source": [
    "#### LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MRDoQvmRpnlI"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0xxcD2N-FNv1"
   },
   "outputs": [],
   "source": [
    "# initializing the model\n",
    "classifier = Sequential()\n",
    "\n",
    "# taking 64x64 RGB images as input\n",
    "# 1st conv layer followed by 2x2 maxpooling\n",
    "classifier.add(Conv2D(filters = 64, kernel_size = (5, 5), activation = 'relu', input_shape = (64, 64, 3)))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# 2nd conv layer followed by another 2x2 maxpooling\n",
    "classifier.add(Conv2D(filters = 128, kernel_size = (5, 5), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# converting the matrix int vactor\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# 1st fully connected layer\n",
    "classifier.add(Dense(units = 256, activation = 'relu'))\n",
    "classifier.add(Dropout(.5))\n",
    "\n",
    "# 2nd fully connected layer\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(.5))\n",
    "\n",
    "# output layer\n",
    "classifier.add(Dense(units = 50, activation = 'softmax'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dqvoDxSzpnyx"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKCcC_gxqZqy",
    "outputId": "ad6a3b9a-cd5d-49ea-9f0f-1850f5989cfe",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = .1, rotation_range = 25)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('Dataset/Train', \n",
    "                                                 target_size = (64, 64), \n",
    "                                                 batch_size = 32, \n",
    "                                                 class_mode = 'categorical')\n",
    "test_set = test_datagen.flow_from_directory('Dataset/Test', \n",
    "                                            target_size = (64, 64), \n",
    "                                            batch_size = 32, \n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps Calculation:\n",
    "<br>\n",
    "steps = no. of images // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LOSwbPw6qZuo",
    "outputId": "d0165bfc-550c-4ce0-fc22-09d4c8c1884a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 25s 47ms/step - loss: 3.8787 - accuracy: 0.0299 - val_loss: 2.8196 - val_accuracy: 0.2732\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 2.9019 - accuracy: 0.2030 - val_loss: 1.2812 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 1.9539 - accuracy: 0.4184 - val_loss: 0.9222 - val_accuracy: 0.7567\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 1.5385 - accuracy: 0.5342 - val_loss: 0.6429 - val_accuracy: 0.8347\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 18s 47ms/step - loss: 1.3247 - accuracy: 0.5982 - val_loss: 0.5208 - val_accuracy: 0.8622\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 1.1161 - accuracy: 0.6638 - val_loss: 0.4209 - val_accuracy: 0.8841\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 0.9916 - accuracy: 0.7028 - val_loss: 0.3941 - val_accuracy: 0.8858\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 17s 47ms/step - loss: 0.9096 - accuracy: 0.7268 - val_loss: 0.3563 - val_accuracy: 0.9009\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 0.8055 - accuracy: 0.7511 - val_loss: 0.3043 - val_accuracy: 0.9106\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 0.7712 - accuracy: 0.7668 - val_loss: 0.3061 - val_accuracy: 0.9140\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 17s 46ms/step - loss: 0.7371 - accuracy: 0.7797 - val_loss: 0.2920 - val_accuracy: 0.9180\n",
      "Epoch 12/100\n",
      "179/375 [=============>................] - ETA: 8s - loss: 0.7350 - accuracy: 0.7839"
     ]
    }
   ],
   "source": [
    "classifier.fit(training_set, steps_per_epoch = 375, epochs = 100,\n",
    "                        validation_data = test_set, validation_steps = 93)\n",
    "\n",
    "\n",
    "# Save the model to disk\n",
    "classifier_json = classifier.to_json()\n",
    "with open(\"LeNetE100.json\", \"w\") as json_file:\n",
    "    json_file.write(classifier_json)\n",
    "    \n",
    "classifier.save_weights(\"LeNetE100.h5\")\n",
    "print('Saved model to disk')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CSE299_BHRCR_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
